{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainable AI: een kijkje achter de schermen\n",
    "In deze omgeving staan wat voorbeelden van het gebruik van AI modellen en de uitlegbaarheid daarvan.\n",
    "In principe hoef je zelf niets te programmeren. Je hoeft alleen op 'execute cell' te klikken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De onderstaande code wordt gebruikt om de benodigde tools te laden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data voorbereiding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu laden we de data. We gaan kijken naar de Palmer Archipelago (Antarctica) penguin dataset, voor meer informatie: https://github.com/allisonhorst/palmerpenguins/blob/main/README.md."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lees de data\n",
    "df = pd.read_csv('./data/penguins_size.csv')\n",
    "df = df.dropna()\n",
    "df = df[~(df['sex'] == '.')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print de data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gaan voorspellen of een penguin een mannetje (MALE) of vrouwtje is (FEMALE) aan de hand van de attributen (ook wel features genoemd): snavellengte (culmen_length_mm), snavel hoogte (culmen_depth_mm), vleugel lengte (flipper_length_mm) en gewicht (body_mass_g)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = df.drop(['species', 'island', 'sex'], axis=1)\n",
    "y = df['sex']\n",
    "class_names = [str(feat) for feat in list(set(y))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We verdelen de data in twee groepen: een training en een test groep. De training groep wordt gebruikt om een model te bouwen. De test groep wordt gebruikt om te kijken hoe goed het model het doet op data die het niet eerder heeft gezien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intrinsiek explainable modellen - De beslisboom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met een beslisboom kunnen we een voorspellend model maken dat intrinsiek te begrijpen is door de mens. Hieronder bouwen een model met een simpele tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = DecisionTreeClassifier(random_state=42, max_depth=2)\n",
    "model_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kunnen berekenen hoe goed ons model is. Dit doen we door te kijken hoeveel procent van de datapunten in de 'test data' goed geclassificeerd wordt. Dit heet de accuracy van het model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the baseline accuracy on the test set\n",
    "baseline_accuracy = accuracy_score(y_test, model_dt.predict(X_test))\n",
    "print(f'Baseline Accuracy: {baseline_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder visualizeren we resulterende beslisboom. Ieder blok staat voor een keuze in de dataset. Als een datapunt aan de conditie die op de eerste regel in een blok staat voldoet, gaan we door naar het rechter blok, anders gaan we door naar het linker blok. De onderste regel blokken bepaalt hoe een datapunt geclassificeerd wordt. Dit is aangegeven door de laatste regel in deze blokken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welke aspecten van de data (=features) worden gebruikt voor de classificatie? Hoe bepaalt het model of een penguin een mannetje is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(model_dt, feature_names=X.columns, class_names=class_names, filled=True)\n",
    "plt.title('Decision Tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-hoc explainable modellen - Deep learning en feature permutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In plaats van een beslisboom gebruiken wij nu een deep learning model. Hieronder wordt het model gebouwd en kijken we naar de accuracy van het model op de test data. Hoe verschilt het resultaat met de beslisboom?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Further prepare the data\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = (X_train - X_train.min()) / (X_train.max() - X_train.min())\n",
    "X_test_norm = (X_test - X_train.min()) / (X_train.max() - X_train.min())\n",
    "\n",
    "# Train model\n",
    "model_deep = MLPClassifier(hidden_layer_sizes=(60, 60), alpha=0.01, learning_rate_init=0.1, solver='adam', random_state=42, max_iter=200)\n",
    "model_deep.fit(X_train_norm, y_train)\n",
    "\n",
    "# Get the baseline accuracy on the test set\n",
    "baseline_accuracy = accuracy_score(y_test, model_deep.predict(X_test_norm))\n",
    "print(f'Baseline Accuracy: {baseline_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gaan nu kijken welke features belangrijk zijn volgens ons deep learning model. Dit doen wij door de waardes van features te verstoren en te kijken naar het verschil in de kwaliteit van de voorspellingen.\n",
    "\n",
    "Als wij de waardes van een feature in de dataset verstoren en de voorspelling blijft vrijwel hetzelfde, betekend dit dat het model deze feature nauwelijks nodig is. Als de voorspelling erg verandert is de feature erg belangrijk voor het model.\n",
    "\n",
    "Hier onder zien wij de waardes van de oorspronkelijke features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu verstoren we de culmen_length_mm feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_permuted = X_test.copy()\n",
    "X_permuted['culmen_length_mm'] = np.random.permutation(X_permuted['culmen_length_mm'])\n",
    "X_permuted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We passen het model toe op de verstoorde data en bekijken de prestatie (accuracy) van het model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the new accuracy on the test set\n",
    "permuted_accuracy = accuracy_score(y_test, model_deep.predict(X_permuted))\n",
    "print(f'Permuted Accuracy: {permuted_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wat kunnen wij nu zeggen over de belang van de snavellengte (=culmen_length)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier onder staat een stuk code dat automatisch één voor één de features verstoord en per keer kijkt naar het effect op de prestatie van het model. De nieuwe prestatie wordt vergeleken met de oorspronkelijke prestatie van het model. De grootte van het verschil wordt gezien als de 'importance' van de feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate permutation feature importance\n",
    "def permutation_importance(model, X_test, y_test, metric):\n",
    "    baseline_score = metric(y_test, model.predict(X_test))\n",
    "    importances = {}\n",
    "\n",
    "    for col in X_test.columns:\n",
    "        # Shuffle the values in the column\n",
    "        X_permuted = X_test.copy()\n",
    "        X_permuted[col] = np.random.permutation(X_permuted[col])\n",
    "        \n",
    "        # Calculate the model performance with the permuted feature\n",
    "        permuted_score = metric(y_test, model.predict(X_permuted))\n",
    "        \n",
    "        # The importance is the decrease in performance\n",
    "        importances[col] = baseline_score - permuted_score\n",
    "    return importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gebruiken deze functie nu om het belang van alle features te visualiseren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the feature importances\n",
    "importances = permutation_importance(model_deep, X_test_norm, y_test, accuracy_score)\n",
    "\n",
    "# Sort importances\n",
    "sorted_importances = dict(sorted(importances.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Plot the importances\n",
    "plt.bar(sorted_importances.keys(), sorted_importances.values())\n",
    "plt.xlabel('Features')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Permutation Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wat kunnen we zeggen over de verschillende features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lokale uitleg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De feature permutation methode waar we de features veranderen en kijken hoe dat de model prestatie beïnvloed vertelt ons iets over de globale werking van het model.\n",
    "\n",
    "In sommige situaties kan het gewenst zijn dat we niet alleen deze globale uitleg hebben, maar ook specifieke voorspellingen uit kunnen leggen. Wat we dan willen is de voorspelling + de redenatie voor deze voorspelling.\n",
    "\n",
    "In dit voorbeeld gaan wij kijken naar SHAP (SHapley Additive exPlanations). Dit is een van de populairste methodes voor explainable AI. We gaan tijdens deze workshop niet in op hoe dit precies werkt, voor meer informatie zie: https://github.com/shap/shap#citations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We genereren een SHAP 'explainer' voor ons deep learning model en de dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "shap.initjs()\n",
    "explainer = shap.KernelExplainer(model_deep.predict_proba, np.asarray(X_train_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hebben onze dataset, wij selecteren één penguin waarvan wij willen voorspellen of het een mannetje of vrouwtje is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nadat we penguin 317 hebben geselecteerd, stoppen wij de data in het model en genereren een voorspelling met uitleg.\n",
    "\n",
    "Het idee van de SHAP values is dat de rood/roze features de voorspelling zoals hij is ondersteunen. De features in het blauw wijzen er juist op dat de voorspelling anders zou moeten zijn. De grootte van de balkjes laat zien hoeveel het model gebruik maakt van het bewijs dat elk van de verschillende features levert.\n",
    "\n",
    "In dit geval geven de features culmen_length_mm, culmen_depth_mm en body_mass_g allemaal aan dat de penguin een ... is, terwijl de flipper_length_mm van deze penguin dit in twijfel kan brengen.\n",
    "\n",
    "Pas het id van de penguin (317) aan om naar de voorspelling en uitleg van andere penguins te kijken.\n",
    "\n",
    "Wat kun je uit de uitleg halen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sample = X_test_norm.loc[12]\n",
    "\n",
    "my_sample_df = pd.DataFrame(my_sample).T\n",
    "my_sample_df.columns = X_test_norm.columns\n",
    "print('Predicted sex:', model_deep.predict(my_sample_df)[0])\n",
    "\n",
    "shap_values = explainer.shap_values(my_sample)\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0], my_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
